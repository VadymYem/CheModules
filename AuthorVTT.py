# meta developer: @BlazeFtg / @Author_Che
# requires: pydub speechRecognition moviepy telethon google-generativeai pillow

from io import BytesIO
import os
import tempfile
import logging
import base64
import asyncio

import speech_recognition as srec
from pydub import AudioSegment as auds
from moviepy.editor import VideoFileClip
from telethon.tl.types import (
    DocumentAttributeVideo,
    Message,
    DocumentAttributeAudio,
)
from telethon.errors.rpcerrorlist import MessageNotModifiedError # –î–æ–¥–∞–Ω–æ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –≤–∏–∫–ª—é—á–µ–Ω–Ω—è

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

from .. import loader, utils

logger = logging.getLogger(__name__)

KEY_AUTO_RECOG = "auto_recognition_chats_author_vtt"

@loader.tds
class AuthorVTTModEnhanced(loader.Module):
    """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É —á–µ—Ä–µ–∑ Google Recognition —Ç–∞ Gemini (AI Studio) –∑ –∞–≤—Ç–æ-—Ä–µ–∂–∏–º–æ–º. AuthorVTT"""
    strings = {
        "name": "AuthorVTT: –ì–æ–ª–æ—Å –≤ –¢–µ–∫—Å—Ç",
        "pref": "<b>üéôÔ∏è AuthorVTT\n</b> ",
        "processing": "‚è≥ –û–±—Ä–æ–±–∫–∞...",
        "downloading": "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è...",
        "recognizing": "üó£Ô∏è –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è...",
        "recognized": "üí¨ <b>–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ:</b>\n<i>{}</i>",
        "no_reply": "ü´† –î–∞–π—Ç–µ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –∞—É–¥—ñ–æ/–≥–æ–ª–æ—Å–æ–≤–µ/–≤—ñ–¥–µ–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.",
        "audio_extract_error": "üö´ –ü–æ–º–∏–ª–∫–∞ –≤–∏–ª—É—á–µ–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –≤—ñ–¥–µ–æ.",
        "conversion_error": "üö´ –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –∞—É–¥—ñ–æ.",
        "recognition_error": "üö´ <b>–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è!</b> –ú–æ–∂–ª–∏–≤—ñ –ø—Ä–æ–±–ª–µ–º–∏ –∑ API –∞–±–æ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º –º–æ–≤–∏.",
        "api_error": "üö´ <b>–ü–æ–º–∏–ª–∫–∞ API ({source}):</b> {error}",
        "too_big": "ü´• <b>–ú–µ–¥—ñ–∞—Ñ–∞–π–ª –∑–∞–≤–µ–ª–∏–∫–∏–π –∞–±–æ –∑–∞–¥–æ–≤–≥–∏–π –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è.</b> (–î—ñ—é—Ç—å –ª—ñ–º—ñ—Ç–∏ –Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å/—Ä–æ–∑–º—ñ—Ä)",
        "google_lang": "Google ({})",
        "gemini": "Gemini (–∞–≤—Ç–æ-–º–æ–≤–∞)",
        "auto_on": "‚úÖ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è ({engine}) —É–≤—ñ–º–∫–Ω–µ–Ω–æ –≤ —Ü—å–æ–º—É —á–∞—Ç—ñ.</b>",
        "auto_off": "‚õîÔ∏è <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ –≤ —Ü—å–æ–º—É —á–∞—Ç—ñ.</b>",

        "cfg_gemini_key": "–ö–ª—é—á API Google AI Studio (Gemini). –û—Ç—Ä–∏–º–∞—Ç–∏ –∑ https://aistudio.google.com/app/apikey",
        "cfg_ignore_users": "–°–ø–∏—Å–æ–∫ ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ (–∫—Ä—ñ–º —Å–µ–±–µ) –¥–ª—è —ñ–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è –≤ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—ñ.",
        "cfg_silent": "–¢–∏—Ö–∏–π —Ä–µ–∂–∏–º –¥–ª—è –ø–æ–º–∏–ª–æ–∫ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (–±–µ–∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏).",
        "cfg_max_duration_voice": "–ú–∞–∫—Å. —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å (—Å–µ–∫—É–Ω–¥–∏) –¥–ª—è –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–∏—Ö/–∞—É–¥—ñ–æ.",
        "cfg_max_duration_video": "–ú–∞–∫—Å. —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å (—Å–µ–∫—É–Ω–¥–∏) –¥–ª—è –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≤—ñ–¥–µ–æ.",
        "cfg_max_size_mb": "–ú–∞–∫—Å. —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É (–ú–ë) –¥–ª—è –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è.",

        "gemini_token_missing": (
            "<b><emoji document_id=5980953710157632545>‚ùå</emoji>–í—ñ–¥—Å—É—Ç–Ω—ñ–π API-–∫–ª—é—á Google AI (Gemini).</b>\n"
            "–ù–∞–ª–∞—à—Ç—É–π—Ç–µ –π–æ–≥–æ —á–µ—Ä–µ–∑ <code>.config</code> –∫–æ–º–∞–Ω–¥—É –º–æ–¥—É–ª—è.\n"
            "<i>–î–∏–≤. <code>.geminiguide</code> –¥–ª—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π.</i>"
        ),
         "gemini_lib_missing": (
            "<b><emoji document_id=5980953710157632545>‚ùå</emoji>–í—ñ–¥—Å—É—Ç–Ω—è –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ `google-generativeai`.</b>\n"
            "–í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —ó—ó: <code>.pip install google-generativeai</code> —Ç–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç—ñ—Ç—å Hikka."
        ),
        "gemini_instructions": (
            "<emoji document_id=5238154170174820439>üë©‚Äçüéì</emoji> <b>–Ø–∫ –æ—Ç—Ä–∏–º–∞—Ç–∏ API-–∫–ª—é—á Google AI (Gemini):</b>\n"
            "<b>1. –í—ñ–¥–∫—Ä–∏–π—Ç–µ Google AI Studio:</b> <a href=\"https://aistudio.google.com/app/apikey\">aistudio.google.com/app/apikey</a> <emoji document_id=4904848288345228262>üë§</emoji>\n"
            "<b>2. –£–≤—ñ–π–¥—ñ—Ç—å –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Å–≤–æ–≥–æ –æ–±–ª—ñ–∫–æ–≤–æ–≥–æ –∑–∞–ø–∏—Å—É Google.</b>\n"
            "<b>3. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å 'Create API key in new project' (–°—Ç–≤–æ—Ä–∏—Ç–∏ API-–∫–ª—é—á —É –Ω–æ–≤–æ–º—É –ø—Ä–æ–µ–∫—Ç—ñ).</b> <emoji document_id=5431757929940273672>‚ûï</emoji>\n"
            "<b>4. –°–∫–æ–ø—ñ—é–π—Ç–µ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π API-–∫–ª—é—á.</b> <emoji document_id=4916036072560919511>‚úÖ</emoji>\n"
            "<b>5. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ <code>.config</code> –≤ Hikka, –∑–Ω–∞–π–¥—ñ—Ç—å —Ü–µ–π –º–æ–¥—É–ª—å —Ç–∞ –≤—Å—Ç–∞–≤—Ç–µ –∫–ª—é—á —É –ø–æ–ª–µ 'Gemini api key'.</b>"
        ),
    }

    strings_ru = {
        "_cls_doc": "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ Google Recognition –∏ Gemini (AI Studio) —Å –∞–≤—Ç–æ-—Ä–µ–∂–∏–º–æ–º. AuthorVTT",
        "name": "AuthorVTT: –ì–æ–ª–æ—Å –≤ –¢–µ–∫—Å—Ç",
        "pref": "<b>üéôÔ∏è AuthorVTT:</b> ",
        "processing": "‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞...",
        "downloading": "üì• –ó–∞–≥—Ä—É–∑–∫–∞...",
        "recognizing": "üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...",
        "recognized": "üí¨ <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n<i>{}</i>",
        "no_reply": "ü´† –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –∞—É–¥–∏–æ/–≥–æ–ª–æ—Å–æ–≤–æ–µ/–≤–∏–¥–µ–æ —Å–æ–æ–±—â–µ–Ω–∏–µ.",
        "audio_extract_error": "üö´ –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ.",
        "conversion_error": "üö´ –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ.",
        "recognition_error": "üö´ <b>–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è!</b> –í–æ–∑–º–æ–∂–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å API –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞.",
        "api_error": "üö´ <b>–û—à–∏–±–∫–∞ API ({source}):</b> {error}",
        "too_big": "ü´• <b>–ú–µ–¥–∏–∞—Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.</b> (–ü—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –ª–∏–º–∏—Ç—ã –Ω–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å/—Ä–∞–∑–º–µ—Ä)",
        "google_lang": "Google ({})",
        "gemini": "Gemini (–∞–≤—Ç–æ-—è–∑—ã–∫)",
        "auto_on": "‚úÖ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ({engine}) –≤–∫–ª—é—á–µ–Ω–æ –≤ —ç—Ç–æ–º —á–∞—Ç–µ.</b>",
        "auto_off": "‚õîÔ∏è <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –≤ —ç—Ç–æ–º —á–∞—Ç–µ.</b>",
        "cfg_gemini_key": "–ö–ª—é—á API Google AI Studio (Gemini). –ü–æ–ª—É—á–∏—Ç—å —Å https://aistudio.google.com/app/apikey",
        "cfg_ignore_users": "–°–ø–∏—Å–æ–∫ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–∫—Ä–æ–º–µ —Å–µ–±—è) –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏.",
        "cfg_silent": "–¢–∏—Ö–∏–π —Ä–µ–∂–∏–º –¥–ª—è –æ—à–∏–±–æ–∫ –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–±–µ–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –æ–± –æ—à–∏–±–∫–∞—Ö).",
        "cfg_max_duration_voice": "–ú–∞–∫—Å. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫—É–Ω–¥—ã) –¥–ª—è –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö/–∞—É–¥–∏–æ.",
        "cfg_max_duration_video": "–ú–∞–∫—Å. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫—É–Ω–¥—ã) –¥–ª—è –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ.",
        "cfg_max_size_mb": "–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–ú–ë) –¥–ª—è –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.",
        "gemini_token_missing": "<b><emoji document_id=5980953710157632545>‚ùå</emoji>–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API-–∫–ª—é—á Google AI (Gemini).</b>\n–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –µ–≥–æ —á–µ—Ä–µ–∑ <code>.config</code>.\n<i>–°–º. <code>.geminiguide</code> –¥–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.</i>",
        "gemini_lib_missing": "<b><emoji document_id=5980953710157632545>‚ùå</emoji>–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `google-generativeai`.</b>\n–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: <code>.pip install google-generativeai</code> –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Hikka.",
        "gemini_instructions": "<emoji document_id=5238154170174820439>üë©‚Äçüéì</emoji> <b>–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å API-–∫–ª—é—á Google AI (Gemini):</b>\n<b>1. –û—Ç–∫—Ä–æ–π—Ç–µ Google AI Studio:</b> <a href=\"https://aistudio.google.com/app/apikey\">aistudio.google.com/app/apikey</a> <emoji document_id=4904848288345228262>üë§</emoji>\n<b>2. –í–æ–π–¥–∏—Ç–µ —Å –ø–æ–º–æ—â—å—é —Å–≤–æ–µ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ Google.</b>\n<b>3. –ù–∞–∂–º–∏—Ç–µ 'Create API key in new project'.</b> <emoji document_id=5431757929940273672>‚ûï</emoji>\n<b>4. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π API-–∫–ª—é—á.</b> <emoji document_id=4916036072560919511>‚úÖ</emoji>\n<b>5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>.config</code> –≤ Hikka, –Ω–∞–π–¥–∏—Ç–µ —ç—Ç–æ—Ç –º–æ–¥—É–ª—å –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –∫–ª—é—á –≤ 'Gemini api key'.</b>",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "gemini_api_key",
                None,
                lambda: self.strings("cfg_gemini_key"),
                validator=loader.validators.Hidden(),
            ),
            loader.ConfigValue(
                "ignore_users",
                [],
                lambda: self.strings("cfg_ignore_users"),
                validator=loader.validators.Series(validator=loader.validators.TelegramID())
            ),
            loader.ConfigValue(
                "silent",
                False,
                lambda: self.strings("cfg_silent"),
                validator=loader.validators.Boolean()
            ),
             loader.ConfigValue(
                "max_duration_voice",
                300,
                lambda: self.strings("cfg_max_duration_voice"),
                validator=loader.validators.Integer(minimum=10)
            ),
            loader.ConfigValue(
                "max_duration_video",
                120,
                lambda: self.strings("cfg_max_duration_video"),
                validator=loader.validators.Integer(minimum=10)
            ),
            loader.ConfigValue(
                "max_size_mb",
                20,
                lambda: self.strings("cfg_max_size_mb"),
                validator=loader.validators.Integer(minimum=1)
            ),
        )
        self._auto_recog_settings = {}
        self._me_id = -1

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        self_user = await client.get_me()
        if self_user:
            self._me_id = self_user.id
        else:
            logger.error("AuthorVTT: Could not get self user ID during client_ready.")

        self._auto_recog_settings = self.db.get(self.strings("name"), KEY_AUTO_RECOG, {})

        if GEMINI_AVAILABLE and self.config["gemini_api_key"]:
             try:
                 current_gemini_key = getattr(getattr(genai, '_client', None), 'api_key', None)
                 if not current_gemini_key or current_gemini_key != self.config["gemini_api_key"]:
                    genai.configure(api_key=self.config["gemini_api_key"])
                    logger.info("Gemini API configured successfully for AuthorVTT.")
                 else:
                    logger.info("Gemini API already configured with the current key for AuthorVTT.")
             except Exception as e:
                 logger.error(f"Failed to configure Gemini API for AuthorVTT: {e}")

    def _save_auto_recog_settings(self):
        self.db.set(self.strings("name"), KEY_AUTO_RECOG, self._auto_recog_settings)

    async def _recognize_google(self, audio_path: str, lang: str) -> str:
        recog = srec.Recognizer()
        try:
            with srec.AudioFile(audio_path) as audio_file:
                audio_content = recog.record(audio_file)
            return await utils.run_sync(recog.recognize_google, audio_content, language=lang)
        except srec.UnknownValueError: 
            raise ValueError("Google Speech Recognition could not understand audio")
        except srec.RequestError as e: 
            raise ConnectionError(f"Could not request results from Google: {e}")
        except Exception as e: 
            logger.exception("Google recognition internal error")
            raise RuntimeError(f"Google recognition internal error: {e}")

    async def _recognize_gemini(self, audio_path: str, lang: str = None) -> str:
        if not GEMINI_AVAILABLE:
             raise RuntimeError("gemini_lib_missing") 
        if not self.config["gemini_api_key"]:
            raise ValueError("gemini_token_missing") 

        audio_file = None 
        try:
            current_gemini_key = getattr(getattr(genai, '_client', None), 'api_key', None)
            if not current_gemini_key or current_gemini_key != self.config["gemini_api_key"]:
                genai.configure(api_key=self.config["gemini_api_key"])
                logger.info("Gemini API re-configured in _recognize_gemini.")

            logger.debug(f"Gemini: Uploading file {audio_path}")
            audio_file = await utils.run_sync(genai.upload_file, path=audio_path)
            logger.debug(f"Gemini: File {audio_file.name} uploaded, state: {audio_file.state.name}")

            upload_timeout = 300  
            start_time = asyncio.get_event_loop().time()
            while audio_file.state.name == "PROCESSING":
                if asyncio.get_event_loop().time() - start_time > upload_timeout:
                    logger.warning(f"Gemini: File {audio_file.name} processing timed out. Attempting delete.")
                    try: await utils.run_sync(genai.delete_file, name=audio_file.name)
                    except Exception as del_e: logger.error(f"Gemini: Failed to delete timed-out file: {del_e}")
                    raise TimeoutError(f"Gemini file processing timeout ({upload_timeout}s)")
                await asyncio.sleep(2) 
                audio_file = await utils.run_sync(genai.get_file, name=audio_file.name)
                logger.debug(f"Gemini: File {audio_file.name} state: {audio_file.state.name}")

            if audio_file.state.name == "FAILED":
                raise RuntimeError(f"Gemini file processing failed (state: {audio_file.state.name})")
            if audio_file.state.name != "ACTIVE":
                 raise RuntimeError(f"Gemini file not active (state: {audio_file.state.name})")

            model = genai.GenerativeModel(model_name="models/gemini-1.5-flash-latest")
            prompt = "Transcribe the audio file accurately." 
            logger.debug(f"Gemini: Sending request to model for file {audio_file.name}")
            response = await utils.run_sync(
                 model.generate_content, [prompt, audio_file], request_options={"timeout": 300} 
            )

            if not response.candidates:
                 safety_feedback = getattr(response, 'prompt_feedback', None)
                 block_reason = "Unknown safety block"
                 if safety_feedback and hasattr(safety_feedback, 'block_reason') and safety_feedback.block_reason:
                    block_reason = safety_feedback.block_reason.name 
                 logger.warning(f"Gemini: Response blocked. Reason: {block_reason}, Feedback: {safety_feedback}")
                 raise RuntimeError(f"Gemini response blocked (Reason: {block_reason})")

            recognized_text = ""
            try:
                 recognized_text = response.text 
            except ValueError: 
                 if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                     recognized_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, "text"))

            if not recognized_text.strip():
                logger.warning(f"Gemini: Returned empty text. Candidates: {response.candidates}")
                raise RuntimeError("Gemini returned empty text")

            return recognized_text.strip()

        except TimeoutError as e: 
             logger.error(f"Gemini: Timeout error: {e}")
             raise ConnectionError(str(e)) 
        except Exception as e:
            logger.exception(f"Gemini: General error in _recognize_gemini")
            if isinstance(e, (ValueError, RuntimeError, ConnectionError)) and (
                str(e) in ["gemini_token_missing", "gemini_lib_missing"] or
                "Gemini response blocked" in str(e) or
                "Gemini returned empty text" in str(e) or
                "Gemini file processing" in str(e)
            ):
                raise
            if audio_file and hasattr(audio_file, 'name') and audio_file.state.name == "ACTIVE":
                logger.info(f"Gemini: Attempting to delete file {audio_file.name} after error: {e}")
                try: await utils.run_sync(genai.delete_file, name=audio_file.name)
                except Exception as del_e: logger.warning(f"Gemini: Could not delete file {audio_file.name} after error: {del_e}")
            raise RuntimeError(f"Gemini processing error: {e}") 
        finally:
             if audio_file and hasattr(audio_file, 'name') and audio_file.state.name == "ACTIVE":
                 logger.debug(f"Gemini: Deleting file {audio_file.name} in finally block.")
                 try:
                     await utils.run_sync(genai.delete_file, name=audio_file.name)
                     logger.info(f"Gemini: Successfully deleted file {audio_file.name}")
                 except Exception as delete_err:
                     logger.warning(f"Gemini: Could not delete file {audio_file.name} in finally: {delete_err}")


    async def _process_media(
        self,
        message: Message,
        engine: str,
        lang: str = None,
        suppress_status_messages: bool = False
    ) -> str:
        reply = await message.get_reply_message()
        target_message = reply or message

        if not target_message or not target_message.media or \
           (target_message.file.mime_type.split("/")[0] not in ["audio", "video"]):
            raise ValueError("no_reply") 

        is_video = target_message.video is not None
        duration = 0
        size_mb = (target_message.file.size or 0) / 1024 / 1024
        max_duration_cfg = self.config["max_duration_voice"] 

        try:
            doc_attrs, attr_type_cls = (None, None)
            if is_video and target_message.video and hasattr(target_message.video, 'attributes'):
                doc_attrs = target_message.video.attributes
                max_duration_cfg = self.config["max_duration_video"]
                attr_type_cls = DocumentAttributeVideo
            elif (target_message.audio or target_message.voice) and \
                 target_message.document and hasattr(target_message.document, 'attributes'):
                doc_attrs = target_message.document.attributes
                max_duration_cfg = self.config["max_duration_voice"]
                attr_type_cls = DocumentAttributeAudio

            if doc_attrs and attr_type_cls:
                media_attrs = next((attr for attr in doc_attrs if isinstance(attr, attr_type_cls)), None)
                if media_attrs and hasattr(media_attrs, 'duration'):
                    duration = media_attrs.duration
        except Exception as e:
             logger.warning(f"Could not get media duration attributes: {e}")
        
        if (duration != 0 and duration > max_duration_cfg) or \
           (size_mb > self.config["max_size_mb"]):
             logger.warning(f"Media too large/long: duration={duration}s (max={max_duration_cfg}s), size={size_mb:.2f}MB (max={self.config['max_size_mb']}MB)")
             raise ValueError("too_big") 

        status_msg = None
        if not suppress_status_messages:
            status_msg = await utils.answer(message, self.strings("pref") + self.strings("downloading"))

        temp_dir = tempfile.mkdtemp()
        original_media_path = None
        media_name = target_message.file.name or f"media_{target_message.id}.{getattr(target_message.file, 'ext', 'file') or 'file'}"
        
        try:
            original_media_path = await target_message.download_media(file=os.path.join(temp_dir, media_name))
            if not suppress_status_messages and status_msg:
                await status_msg.edit(self.strings("pref") + self.strings("processing"))
            
            audio_source_path_for_api = original_media_path 
            if engine == "google": 
                wav_audio_path = os.path.join(temp_dir, "audio.wav")
                if is_video:
                    logger.debug(f"Extracting audio from video to WAV for Google: {original_media_path}")
                    with VideoFileClip(original_media_path) as video_clip:
                         if video_clip.audio is None:
                              raise ValueError(self.strings("audio_extract_error")) 
                         await utils.run_sync(video_clip.audio.write_audiofile, wav_audio_path, codec="pcm_s16le", logger=None)
                else: 
                    logger.debug(f"Converting audio to WAV for Google: {original_media_path}")
                    audio_segment = await utils.run_sync(auds.from_file, original_media_path)
                    await utils.run_sync(audio_segment.export, wav_audio_path, format="wav")
                audio_source_path_for_api = wav_audio_path
            
            if not os.path.exists(audio_source_path_for_api): 
                 logger.error(f"Audio source for API does not exist: {audio_source_path_for_api}")
                 raise IOError(f"Audio source for API not found: {audio_source_path_for_api}")

            if not suppress_status_messages and status_msg:
                await status_msg.edit(self.strings("pref") + self.strings("recognizing"))

            recognized_text = ""
            if engine == "google":
                if not lang: raise ValueError("Language code required for Google engine") 
                recognized_text = await self._recognize_google(audio_source_path_for_api, lang)
            elif engine == "gemini":
                 recognized_text = await self._recognize_gemini(audio_source_path_for_api, lang) 
            else: 
                raise ValueError(f"Unknown recognition engine: {engine}") 

            if not suppress_status_messages and status_msg:
                pass 
            return recognized_text

        except (ValueError, RuntimeError, IOError, ConnectionError) as e:
            logger.warning(f"Error during media processing in _process_media: {e} (Type: {type(e)})")
            
            if not suppress_status_messages:
                error_display_text = str(e) 
                if str(e) == "no_reply": error_display_text = self.strings("no_reply")
                elif str(e) == "too_big": error_display_text = self.strings("too_big")
                elif str(e) == self.strings("audio_extract_error"): error_display_text = self.strings("audio_extract_error")
                elif str(e) == "gemini_token_missing": error_display_text = self.strings("gemini_token_missing")
                elif str(e) == "gemini_lib_missing": error_display_text = self.strings("gemini_lib_missing")
                elif isinstance(e, ConnectionError):
                    source = "API"
                    if "Google" in str(e): source = "Google API"
                    elif "Gemini" in str(e): source = "Gemini API"
                    error_display_text = self.strings("api_error").format(source=source, error=e)
                elif isinstance(e, IOError): 
                    error_display_text = self.strings("conversion_error") + f" ({e})"
                else: 
                    error_display_text = self.strings("recognition_error") + f" ({e})"
                
                try:
                     if status_msg: 
                         await status_msg.edit(self.strings("pref") + error_display_text)
                     else: 
                         await utils.answer(message, self.strings("pref") + error_display_text)
                except Exception as display_err: 
                     logger.error(f"Failed to display error to user: {display_err}")
            raise 
        finally:
            try:
                for filename in os.listdir(temp_dir): 
                     file_path = os.path.join(temp_dir, filename)
                     if os.path.isfile(file_path) or os.path.islink(file_path):
                         os.unlink(file_path)
                os.rmdir(temp_dir) 
            except Exception as cleanup_err:
                logger.error(f"Failed to cleanup temp dir {temp_dir}: {cleanup_err}")


    async def _handle_recognition_command(self, message: Message, engine: str, lang: str = None):
        """–û–±—Ä–æ–±–Ω–∏–∫ –¥–ª—è –∫–æ–º–∞–Ω–¥ —Ä—É—á–Ω–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è - —Ä–µ–¥–∞–≥—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ–º–∞–Ω–¥–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º."""

        # Helper function to safely edit the command message
        async def _edit_command_message(text_content: str):
            if message.out: # Can only edit our own outgoing messages
                try:
                    # Determine parse mode - Hikka often uses HTML.
                    # Use client's default or explicitly set to "html".
                    parse_html = None
                    # Check if client has parse_mode and it's not None/empty
                    if hasattr(self.client, 'parse_mode') and self.client.parse_mode: 
                        parse_html = self.client.parse_mode
                    
                    if not parse_html: # Default to HTML if not set or client.parse_mode is None/empty
                        parse_html = "html"
                        
                    await message.edit(text_content, parse_mode=parse_html)
                except MessageNotModifiedError:
                    pass # Message content is the same, no action needed
                except Exception as e_edit:
                    logger.error(f"Failed to edit message (ID: {message.id}) directly: {e_edit}")

        try:
            await _edit_command_message(self.strings("pref") + self.strings("processing"))

            recognized_text = await self._process_media(
                message,
                engine,
                lang,
                suppress_status_messages=True 
            )

            final_text_output = self.strings("recognized").format(recognized_text)
            await _edit_command_message(self.strings("pref") + final_text_output)

        except Exception as e:
            logger.warning(f"Error in _handle_recognition_command (engine: {engine}): {e} (Type: {type(e)})")
            
            error_message_text = ""
            error_key = str(e) 

            if error_key in self.strings: 
                try: error_message_text = self.strings(error_key).format(error=str(e)) 
                except KeyError: error_message_text = self.strings(error_key) 
            elif isinstance(e, ConnectionError): 
                source = "API" 
                if "Google" in str(e): source = "Google API"
                elif "Gemini" in str(e): source = "Gemini API"
                error_message_text = self.strings("api_error").format(source=source, error=str(e))
            elif isinstance(e, IOError): 
                 error_message_text = self.strings("conversion_error") + f" ({str(e)})"
            else: 
                error_message_text = self.strings("recognition_error") + f" ({str(e)})"
            
            try:
                await _edit_command_message(self.strings("pref") + error_message_text)
            except Exception as edit_final_error: 
                logger.error(f"Secondary log: Failed to edit command message with final error: {edit_final_error}")

    @loader.owner
    @loader.command(alias="vua", ru_doc=".vua <—Ä–µ–ø–ª–∞–π> - –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π (Google)")
    async def vuacmd(self, message: Message):
        """–†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é (Google)"""
        await self._handle_recognition_command(message, "google", "uk-UA")

    @loader.owner
    @loader.command(alias="vru", ru_doc=".vru <—Ä–µ–ø–ª–∞–π> - –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä—É—Å—Å–∫–∏–π (Google)")
    async def vrucmd(self, message: Message):
        """–†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ä–æ—Å—ñ–π—Å—å–∫–æ—é (Google)"""
        await self._handle_recognition_command(message, "google", "ru-RU")

    @loader.owner
    @loader.command(alias="ven", ru_doc=".ven <—Ä–µ–ø–ª–∞–π> - –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (Google)")
    async def vencmd(self, message: Message):
        """–†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é (Google)"""
        await self._handle_recognition_command(message, "google", "en-US")

    @loader.owner
    @loader.command(alias="vai", ru_doc=".vai <—Ä–µ–ø–ª–∞–π> - –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å (Gemini, –∞–≤—Ç–æ-—è–∑—ã–∫)")
    async def vaicmd(self, message: Message):
        """–†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –º–æ–≤–ª–µ–Ω–Ω—è (Gemini, –∞–≤—Ç–æ-–º–æ–≤–∞)"""
        await self._handle_recognition_command(message, "gemini")

    async def _toggle_auto_recog(self, message: Message, engine: str, lang: str = None):
        chat_id = utils.get_chat_id(message)
        chat_id_str = str(chat_id)
        current_setting = self._auto_recog_settings.get(chat_id_str)
        new_setting = {"engine": engine, "lang": lang}

        response_text_key = ""
        engine_name_display = engine.capitalize() 

        if current_setting == new_setting: 
            self._auto_recog_settings.pop(chat_id_str, None)
            response_text_key = "auto_off"
        else: 
            if engine == "gemini": 
                 if not GEMINI_AVAILABLE:
                      await utils.answer(message, self.strings("pref") + self.strings("gemini_lib_missing"))
                      return
                 if not self.config["gemini_api_key"]:
                      await utils.answer(message, self.strings("pref") + self.strings("gemini_token_missing"))
                      return

            self._auto_recog_settings[chat_id_str] = new_setting
            response_text_key = "auto_on"
            if engine == 'google' and lang: engine_name_display = self.strings('google_lang').format(lang)
            elif engine == 'gemini': engine_name_display = self.strings('gemini')
        
        self._save_auto_recog_settings()
        final_response_text = self.strings(response_text_key)
        if response_text_key == "auto_on":
            final_response_text = final_response_text.format(engine=engine_name_display)
        
        await utils.answer(message, self.strings("pref") + final_response_text)


    @loader.owner
    @loader.command(alias="autoua", ru_doc="–í–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ (Google) –≤ —á–∞—Ç–µ")
    async def autouacmd(self, message: Message):
        """–ü–µ—Ä–µ–º–∫–Ω—É—Ç–∏ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é (Google) –≤ —á–∞—Ç—ñ"""
        await self._toggle_auto_recog(message, "google", "uk-UA")

    @loader.owner
    @loader.command(alias="autoru", ru_doc="–í–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ (Google) –≤ —á–∞—Ç–µ")
    async def autorucmd(self, message: Message):
        """–ü–µ—Ä–µ–º–∫–Ω—É—Ç–∏ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä–æ—Å—ñ–π—Å—å–∫–æ—é (Google) –≤ —á–∞—Ç—ñ"""
        await self._toggle_auto_recog(message, "google", "ru-RU")

    @loader.owner
    @loader.command(alias="autoen", ru_doc="–í–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ (Google) –≤ —á–∞—Ç–µ")
    async def autoencmd(self, message: Message):
        """–ü–µ—Ä–µ–º–∫–Ω—É—Ç–∏ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é (Google) –≤ —á–∞—Ç—ñ"""
        await self._toggle_auto_recog(message, "google", "en-US")

    @loader.owner
    @loader.command(alias="autoai", ru_doc="–í–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (Gemini, –∞–≤—Ç–æ-—è–∑—ã–∫) –≤ —á–∞—Ç–µ")
    async def autoaicmd(self, message: Message):
        """–ü–µ—Ä–µ–º–∫–Ω—É—Ç–∏ –∞–≤—Ç–æ-—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (Gemini, –∞–≤—Ç–æ-–º–æ–≤–∞) –≤ —á–∞—Ç—ñ"""
        await self._toggle_auto_recog(message, "gemini")

    @loader.watcher(only_media=True, no_cmd=True)
    async def watcher(self, message: Message):
        if not isinstance(message, Message): return 
        chat_id = utils.get_chat_id(message)
        settings = self._auto_recog_settings.get(str(chat_id))
        if not settings: return 

        is_video = message.video is not None and not getattr(message, 'gif', False)
        is_audio = message.audio is not None
        is_voice = getattr(message, 'voice', None) is not None or \
                   (message.document and any(
                       isinstance(attr, DocumentAttributeAudio) and getattr(attr, 'voice', False)
                       for attr in getattr(message.document, 'attributes', [])
                   ))
        if not (is_video or is_audio or is_voice): return 

        sender = await message.get_sender()
        if not sender or sender.bot: return 
        if self._me_id != -1 and message.sender_id != self._me_id and message.sender_id in self.config["ignore_users"]:
            return

        engine, lang = settings["engine"], settings["lang"]
        logger.debug(f"AuthorVTT Watcher: Triggered for chat {chat_id} by {message.sender_id} (engine: {engine})")
        try:
            recognized_text = await self._process_media(message, engine, lang, suppress_status_messages=False)
            
            if recognized_text and recognized_text.strip(): 
                 await message.reply(self.strings("recognized").format(recognized_text))
            else:
                 logger.warning(f"AuthorVTT Watcher: Empty text received for chat {chat_id}. No reply sent.")

        except Exception as e:
            logger.warning(f"AuthorVTT Watcher: Error processing message in chat {chat_id} (engine {engine}): {e}. "
                           "Error display is handled by _process_media if not in silent mode.")

    @loader.command(ru_doc="–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –ø–æ–ª—É—á–µ–Ω–∏—é API –∫–ª—é—á–∞ Gemini")
    async def geminiguide(self, message: Message):
        """–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è API –∫–ª—é—á–∞ Gemini"""
        await utils.answer(message, self.strings('gemini_instructions'))
